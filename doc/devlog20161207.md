# 2016-12-07 Wed. to 2016-12-11 Sun.

## パラメーター

- layer
    - n_node: 5 ~ 100
    - weight: 'zeros', 'ones', 'random_normal', 'truncated_normal'
    - stddev: 0.0001 ~ 0.1
    - bias: 'zeros', 'ones'
    - activ_func: '', 'relu', 'tanh', 'softmax'

- trainer
    - optimizer: GradientDescentOptimizer, AdamOptimizer
    - learning rate: 0.0001 ~ 0.1

- batch size: 10 ~ 100
- num iter: 1 ~ 10000


最初に層の数を指定する。

```python
node_params = [50, 50]

model_params = [
    {
        'weight' = 'random_normal'
        'stddev' = 0.01
        'bias' = 'zeros'
        'activ' = 'relu'
    },
    {
        'weight' = 'random_normal'
        'stddev' = 0.01
        'bias' = 'zeros'
        'activ' = 'relu'
    },
   {
        'weight' = 'random_normal'
        'stddev' = 0.01
        'bias' = 'zeros'
        'activ' = ''
    }

other_params = {
    'trainer': 0
    'learnig_rate': 0.01
    'batch_size': 10
    'n_iter': 10
}


# FizzBuzz
X  = tf.placeholder(tf.float32, [None, n_X])
H1 = self.__make_layer(X, n_X, n_hidden[0], 'random_normal', 'zeros', 'relu')
Y  = self.__make_layer(H1, n_hidden[0], n_Y, 'random_normal', 'zeros', '')
Y_ = tf.placeholder(tf.float32, [None, n_Y])
```
